{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpAdvEOA03JkXMGelwlN2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShareAndShine/Lemalabs/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5V1EwtLuNIo"
      },
      "source": [
        "s1 = 'My name is ------------------ Pawan & *#Raj'\n",
        "s2 = 'Today is very ****** good day'\n",
        "s3 = 'How can I _ help you ?'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u846b-d1vbhs"
      },
      "source": [
        "# Step 1 - convert text into lowercase\n",
        "s1 = s1.lower() # In NLP step 1 is always convert into lower case then tokenize and clean\n",
        "s2 = s2.lower()\n",
        "s3 = s3.lower()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skwBN2P1wOjc",
        "outputId": "0798bb8c-dc73-41ed-c3c8-7556b74f77f9"
      },
      "source": [
        "# Step 2 - Tokenize \n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-AuRlecwbLI"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer('\\w+')\n",
        "\n",
        "def tok(x): # helper method to split words in the sentence and holds in an array\n",
        "  return (tokenizer.tokenize(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZjTup1RwyX0",
        "outputId": "a8aafcac-64e7-48a8-e065-8b24e1dab3a3"
      },
      "source": [
        "print(tok(s1))\n",
        "print(tok(s2))\n",
        "print(tok(s3))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'name', 'is', 'pawan', 'raj']\n",
            "['today', 'is', 'very', 'good', 'day']\n",
            "['how', 'can', 'i', '_', 'help', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWh1ZJZKx6M0",
        "outputId": "49a5afe2-0500-4893-cfeb-76518b21b704"
      },
      "source": [
        "s1 = tok(s1)\n",
        "s2 = tok(s2)\n",
        "s3 = tok(s3)\n",
        "s1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my', 'name', 'is', 'pawan', 'raj']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIIC65auzIYq",
        "outputId": "dcb5d924-0773-47fe-87a4-402ee51d24e5"
      },
      "source": [
        "# Step 3 - Cleaning\n",
        "\n",
        "# Remove any spill over special characters from the above step which do not add any value\n",
        "\n",
        "import re # import regular expression python lib \n",
        "\n",
        "pattern =\"_\"\n",
        "\n",
        "s3 = [re.sub(pattern,'',i) for i in s3]\n",
        "s3"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['how', 'can', 'i', '', 'help', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMdWhMY902ST"
      },
      "source": [
        "**Sample **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lqE4DppzwdL",
        "outputId": "1e209188-ff50-47b5-eb43-0f5d1bf19d36"
      },
      "source": [
        "ex = 'I am _ Rajesh 15'\n",
        "\n",
        "ex = tok(ex.lower())\n",
        "ex\n",
        "\n",
        "# Remove special characters\n",
        "pattern = \"_\"\n",
        "ex = [re.sub(pattern,'',i) for i in ex]\n",
        "ex\n",
        "\n",
        "# Remove numbers\n",
        "pattern = \"[0-9]\"\n",
        "ex = [re.sub(pattern,'',i) for i in ex]\n",
        "ex\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', '', 'rajesh', '']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQB5zxZu1Whk",
        "outputId": "e0f015fc-4a18-4c8c-a563-d7c0d27211c2"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNW1Ojut1mRK"
      },
      "source": [
        "sw = stopwords.words('english')\n",
        "sw # lists all stops words"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLbyK_Mn2QXY",
        "outputId": "a3b4dc75-db60-483f-eb6e-c338279263fb"
      },
      "source": [
        "s1 = [ word for word in s1 if word not in sw]\n",
        "s2 = [ word for word in s2 if word not in sw]\n",
        "s3 = [ word for word in s3 if word not in sw]\n",
        "s3"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'help']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrCgxkNA55_h",
        "outputId": "977d496a-1cc7-411c-a67b-739132b698c2"
      },
      "source": [
        "# LETS DO ALL THE ABOVE STEPS IN ONE GO WITH SKLEARN ALGORITHUM\n",
        "\n",
        "s1 = 'Send us your password'\n",
        "s2 = 'Send us your review'\n",
        "s3 = 'Review your password'\n",
        "s4 = 'Review us'\n",
        "s5 = 'Send your password'\n",
        "s6 = 'Send us your account'\n",
        "\n",
        "# create an array to hold all sentences\n",
        "x = [s1, s2, s3, s4, s5, s6]\n",
        "x"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Send us your password',\n",
              " 'Send us your review',\n",
              " 'Review your password',\n",
              " 'Review us',\n",
              " 'Send your password',\n",
              " 'Send us your account']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}